<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Chatbot mit Gemini</title>
  <style>
    body {
      background-color: #000;
      color: #fff;
      font-family: Arial, sans-serif;
    }
    #chatbox {
      width: 100%;
      height: 400px;
      overflow-y: scroll;
      border: 1px solid #fff;
      padding: 10px;
      background-color: #000;
      color: #fff;
    }
    #onAir {
      color: red;
      font-size: 1.5em;
      display: none;
    }
    #recordButton {
      margin-top: 10px;
      padding: 10px;
      background-color: green;
      color: white;
      border: none;
      cursor: pointer;
    }
    #recordButton.stop {
      background-color: red;
    }
    #browserMessages {
      margin-top: 10px;
      padding: 10px;
      border: 1px solid #fff;
      background-color: #000;
      color: #fff;
    }
  </style>
</head>
<body>
  <div id="onAir">On Air</div>
  <div id="chatbox"></div>
  <button id="recordButton">Verbindung starten</button>
  <div id="browserMessages"></div>
  <script>
    const APP_ID = 'acP7SyEGEm8ge7GkW1h9DStkqe6gQRfy2XIlDkST';
    const REST_API_KEY = 'u74saAzlTt9vic4uL34twMnouLCeoy1AgKlmXwqZ';
    
    let audioContext;
    let recorder;
    let audioData = [];
    const recordButton = document.getElementById('recordButton');
    const chatbox = document.getElementById('chatbox');
    const onAir = document.getElementById('onAir');
    const browserMessages = document.getElementById('browserMessages');

    // Inline AudioWorkletProcessor-Code als String
    const processorCode = `
      class RecorderProcessor extends AudioWorkletProcessor {
        constructor() {
          super();
          this.buffer = [];
        }

        process(inputs) {
          const input = inputs[0];
          if (input.length > 0) {
            const samples = input[0]; // Erster Kanal
            this.buffer.push(...samples);
            this.port.postMessage({ eventType: 'data', audioBuffer: samples });
          }
          return true; // Prozessor bleibt aktiv
        }
      }

      registerProcessor('recorder-processor', RecorderProcessor);
    `;

    // AudioWorklet-Prozessor als Blob laden
    async function loadAudioWorklet() {
      audioContext = new AudioContext();
      const blob = new Blob([processorCode], { type: 'application/javascript' });
      const blobURL = URL.createObjectURL(blob);
      await audioContext.audioWorklet.addModule(blobURL);
    }

    recordButton.addEventListener('click', async () => {
      if (!recorder) {
        if (!audioContext) await loadAudioWorklet();
        startRecording();
      } else {
        stopRecording();
      }
    });

    // Audioaufnahme starten
    function startRecording() {
      navigator.mediaDevices.getUserMedia({ audio: true })
        .then(stream => {
          const input = audioContext.createMediaStreamSource(stream);
          recorder = new AudioWorkletNode(audioContext, 'recorder-processor');
          input.connect(recorder);
          recorder.port.onmessage = (e) => {
            if (e.data.eventType === 'data') {
              audioData.push(e.data.audioBuffer);
            }
          };
          recordButton.textContent = 'Verbindung stoppen';
          recordButton.classList.add('stop');
          onAir.style.display = 'block';
        })
        .catch(err => {
          console.error('Mikrofonzugriff fehlgeschlagen:', err);
          browserMessages.innerHTML += `<p>Fehler: Mikrofonzugriff fehlgeschlagen - ${err.message}</p>`;
        });
    }

    // Audioaufnahme stoppen
    function stopRecording() {
      recorder.port.postMessage({ eventType: 'stop' });
      const wavBlob = encodeWAV(audioData, audioContext.sampleRate);
      const reader = new FileReader();
      reader.readAsDataURL(wavBlob);
      reader.onloadend = () => {
        const base64Audio = reader.result.split(',')[1]; // Nur Base64-Daten
        sendAudioToBackend(base64Audio);
      };
      recordButton.textContent = 'Verbindung starten';
      recordButton.classList.remove('stop');
      onAir.style.display = 'none';
      audioData = [];
      recorder = null;
    }

    // WAV-Datei erstellen
    function encodeWAV(audioData, sampleRate) {
      const numSamples = audioData.reduce((acc, val) => acc + val.length, 0);
      const buffer = new ArrayBuffer(44 + numSamples * 2);
      const view = new DataView(buffer);

      // WAV-Header
      writeString(view, 0, 'RIFF');
      view.setUint32(4, 36 + numSamples * 2, true);
      writeString(view, 8, 'WAVE');
      writeString(view, 12, 'fmt ');
      view.setUint32(16, 16, true);
      view.setUint16(20, 1, true);
      view.setUint16(22, 1, true);
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, sampleRate * 2, true);
      view.setUint16(32, 2, true);
      view.setUint16(34, 16, true);
      writeString(view, 36, 'data');
      view.setUint32(40, numSamples * 2, true);

      // Audiodaten
      let offset = 44;
      audioData.forEach(samples => {
        samples.forEach(sample => {
          const s = Math.max(-1, Math.min(1, sample));
          view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
          offset += 2;
        });
      });

      return new Blob([view], { type: 'audio/wav' });
    }

    function writeString(view, offset, string) {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    }

    // Audio an Backend senden
    async function sendAudioToBackend(base64Audio) {
      try {
        const response = await fetch('https://parseapi.back4app.com/functions/processAudio', {
          method: 'POST',
          headers: {
            'X-Parse-Application-Id': APP_ID,
            'X-Parse-REST-API-Key': REST_API_KEY,
            'Content-Type': 'application/json'
          },
          body: JSON.stringify({ audio: base64Audio })
        });
        const data = await response.json();
        const botResponse = data.result; // Ergebnis der Cloud-Funktion
        chatbox.innerHTML += `<p>Bot: ${botResponse}</p>`;
        speak(botResponse); // Text-to-Speech
      } catch (error) {
        console.error('Fehler beim Senden:', error);
        browserMessages.innerHTML += `<p>Fehler: ${error.message}</p>`;
      }
    }

    // Text-to-Speech mit Web Speech API
    function speak(text) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'de-DE'; // Deutsche Sprache
      window.speechSynthesis.speak(utterance);
    }
  </script>
</body>
</html>
